apiVersion: v1
kind: Template
metadata:  
  name: nuxeo-backings
  namespace: openshift
  annotations:
    description: |
      This templates setup the backing service needed to run a Nuxeo cluster. Once  MongoDB, ElasticSearch and Kafka are 
      started and ready, you can start one of the Nuxeo cluster flavor (image based or S2i based)
    iconClass: icon-java
    tags: java, nuxeo
parameters:
  - description: The name for the application.
    name: APPLICATION_NAME
    value: nuxeo-backings
    required: true
  - description: Size of persistent storage for MongoDB.
    name: VOLUME_MONGODB_CAPACITY
    value: 5Gi
    required: true
  - description: Name of the MongoDB replica set
    name: MONGODB_REPLICASET_NAME
    value: rs0
    required: true
  - description: Size of persistent storage for Elasticsearch.
    name: VOLUME_ELASTICSEARCH_CAPACITY
    value: 10Gi
    required: true
  - description: Elasticsearch cluster name
    name: ELASTICSEARCH_CLUSTER_NAME
    value: nuxeo
    required: true
  - description: Elasticsearch Memory
    name: ELASTICSEARCH_CLUSTER_MEMORY
    value: 256m
    required: true
  - description: Size of persistent storage for Zookeper.
    name: VOLUME_ZOOKEEPER_CAPACITY
    value: 10Gi
  - description: Size of persistent storage for Kafka.
    name: VOLUME_KAFKA_CAPACITY
    value: 10Gi


objects:

- kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch-config
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: config
  apiVersion: v1
  data:
    log4j2.properties: |-
      appender.rolling.type = RollingFile 
      appender.rolling.name = rolling
      appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log 
      appender.rolling.layout.type = PatternLayout
      appender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] %marker%.-10000m%n
      appender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.log.gz 
      appender.rolling.policies.type = Policies
      appender.rolling.policies.time.type = TimeBasedTriggeringPolicy 
      appender.rolling.policies.time.interval = 1 
      appender.rolling.policies.time.modulate = true 
      appender.rolling.policies.size.type = SizeBasedTriggeringPolicy 
      appender.rolling.policies.size.size = 256MB 
      appender.rolling.strategy.type = DefaultRolloverStrategy
      appender.rolling.strategy.fileIndex = nomax
      appender.rolling.strategy.action.type = Delete 
      appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}
      appender.rolling.strategy.action.condition.type = IfFileName 
      appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* 
      appender.rolling.strategy.action.condition.nested_condition.type = IfAccumulatedFileSize 
      appender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB 
    elasticsearch.yml: |-
      cluster:
        name: ${CLUSTER_NAME}

      node:
        master: ${NODE_MASTER}
        data: ${NODE_DATA}

      network.host: ${NETWORK_HOST}

      path:
        data: /usr/share/elasticsearch/data
        logs: /usr/share/elasticsearch/data/log
        work: /usr/share/elasticsearch/data/work
        plugins: /usr/share/elasticsearch/plugins

      bootstrap.mlockall: true

      http:
        enabled: ${HTTP_ENABLE}
        compression: true
        cors:
          enabled: ${HTTP_CORS_ENABLE}
          allow-origin: ${HTTP_CORS_ALLOW_ORIGIN}

      cloud:
        kubernetes:
          service: ${DISCOVERY_SERVICE}
          namespace: ${NAMESPACE}
      discovery:
        type: kubernetes
        zen:
          minimum_master_nodes: ${NUMBER_OF_MASTERS}

      index:
          number_of_shards: ${NUMBER_OF_SHARDS}
          number_of_replicas: ${NUMBER_OF_REPLICAS}

    logging.yml: |
      # you can override this using by setting a system property, for example -Des.logger.level=DEBUG
      es.logger.level: INFO
      rootLogger: ${es.logger.level}, console
      logger:
        # log action execution errors for easier debugging
        action: DEBUG
        # reduce the logging for aws, too much is logged under the default INFO
        com.amazonaws: WARN

      appender:
        console:
          type: console
          layout:
            type: consolePattern
            conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"

- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch-discovery
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: master
  spec:
    selector:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: master
    ports:
    - name: transport
      port: 9300
      protocol: TCP

- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: ${APPLICATION_NAME}-es-client
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: client
  spec:
    replicas: 2
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: elasticsearch
          role: client        
      spec:
        serviceAccountName: elasticsearch
        containers:
        - name: ${APPLICATION_NAME}-es-client          
          securityContext:
            privileged: false
            capabilities:
              add:
                - IPC_LOCK
                - SYS_RESOURCE
          image: nuxeo/docker-elasticsearch-kubernetes:2.4.5
          imagePullPolicy: Always
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: "CLUSTER_NAME"
            value: ${ELASTICSEARCH_CLUSTER_NAME}
          - name: NODE_MASTER
            value: "false"
          - name: NODE_DATA
            value: "false"
          - name: HTTP_ENABLE
            value: "true"
          - name: "ES_JAVA_OPTS"
            value: "-Xms${ELASTICSEARCH_CLUSTER_MEMORY} -Xmx${ELASTICSEARCH_CLUSTER_MEMORY}"
          - name: DISCOVERY_SERVICE
            value: ${APPLICATION_NAME}-elasticsearch-discovery
          ports:
          - containerPort: 9200
            name: http
            protocol: TCP
          - containerPort: 9300
            name: transport
            protocol: TCP
          volumeMounts:
          - name: storage
            mountPath: /data
          - name: config
            mountPath: /usr/share/elasticsearch/config
        initContainers:
        - command:
            - sysctl
            - '-w'
            - vm.max_map_count=262144
          image: busybox
          imagePullPolicy: IfNotPresent
          name: sysctl
          securityContext:
            privileged: true
        volumes:
            - emptyDir:
                medium: ""
              name: "storage"
            - name: config
              configMap:
                name: ${APPLICATION_NAME}-elasticsearch-config

- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: client
  spec:
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: client
    ports:
    - name: http
      port: 9200
      protocol: TCP



- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: ${APPLICATION_NAME}-es-master
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: master
  spec:
    replicas: 3
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: elasticsearch
          role: master        
      spec:
        serviceAccountName: elasticsearch
        containers:
        - name: es-master
          securityContext:
            privileged: false
            capabilities:
              add:
                - IPC_LOCK
                - SYS_RESOURCE
          image: nuxeo/docker-elasticsearch-kubernetes:2.4.5
          imagePullPolicy: Always
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: "CLUSTER_NAME"
            value: ${ELASTICSEARCH_CLUSTER_NAME}
          - name: "NUMBER_OF_MASTERS"
            value: "2"
          - name: NODE_MASTER
            value: "true"
          - name: NODE_INGEST
            value: "false"
          - name: NODE_DATA
            value: "false"
          - name: HTTP_ENABLE
            value: "false"
          - name: "ES_JAVA_OPTS"
            value: "-Xms${ELASTICSEARCH_CLUSTER_MEMORY} -Xmx${ELASTICSEARCH_CLUSTER_MEMORY}"
          - name: DISCOVERY_SERVICE
            value: ${APPLICATION_NAME}-elasticsearch-discovery
          ports:
          - containerPort: 9300
            name: transport
            protocol: TCP
          volumeMounts:
          - name: storage
            mountPath: /data
          - name: config
            mountPath: /usr/share/elasticsearch/config
        initContainers:
        - command:
            - sysctl
            - '-w'
            - vm.max_map_count=262144
          image: busybox
          imagePullPolicy: IfNotPresent
          name: sysctl
          securityContext:
            privileged: true
        volumes:
            - emptyDir:
                medium: ""
              name: "storage"
            - name: config
              configMap:
                name: ${APPLICATION_NAME}-elasticsearch-config        

- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch-data
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: data
  spec:
    ports:
    - port: 9300
      name: transport
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: data


- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch
    labels:
      app: ${APPLICATION_NAME}
      component: elasticsearch
      role: data
  spec:
    serviceName: ${APPLICATION_NAME}-elasticsearch-data
    replicas: 3
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: elasticsearch
          role: data
      spec:
        serviceAccountName: elasticsearch
        containers:
        - name: es-data
          securityContext:
            privileged: true
            capabilities:
              add:
                - IPC_LOCK
          image: nuxeo/docker-elasticsearch-kubernetes:2.4.5
          imagePullPolicy: Always
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: "CLUSTER_NAME"
            value: ${ELASTICSEARCH_CLUSTER_NAME}
          - name: NODE_MASTER
            value: "false"
          - name: NODE_INGEST
            value: "false"
          - name: HTTP_ENABLE
            value: "false"
          - name: DISCOVERY_SERVICE
            value: ${APPLICATION_NAME}-elasticsearch-discovery
          - name: "ES_JAVA_OPTS"
            # TODO: review values
            value: "-Xms${ELASTICSEARCH_CLUSTER_MEMORY} -Xmx${ELASTICSEARCH_CLUSTER_MEMORY}"
          ports:
          - containerPort: 9300
            name: transport
            protocol: TCP
          volumeMounts:
          - name: data
            mountPath: /data
          - name: config
            mountPath: /usr/share/elasticsearch/config
        initContainers:
        - command:
            - sysctl
            - '-w'
            - vm.max_map_count=262144
          image: busybox
          imagePullPolicy: IfNotPresent
          name: sysctl
          securityContext:
            privileged: true
        volumes:
          - name: config
            configMap:
              name: ${APPLICATION_NAME}-elasticsearch-config

    volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: ${APPLICATION_NAME}   
        annotations:
          volume.beta.kubernetes.io/storage-class: aws-fast
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_ELASTICSEARCH_CAPACITY}



- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-mongo
    labels:
      app: ${APPLICATION_NAME}
      component: mongo
  spec:
    ports:
    - port: 27017
      targetPort: 27017
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: mongo

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-mongo
  spec:
    serviceName: ${APPLICATION_NAME}-mongo
    replicas: 3
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: mongo          
      spec:
        terminationGracePeriodSeconds: 10
        containers:
          - name: mongo
            image: mongo
            command:
              - mongod
              - "--replSet"
              - ${MONGODB_REPLICASET_NAME}
              - "--smallfiles"
              - "--noprealloc"
            ports:
              - containerPort: 27017
            volumeMounts:
              - name: data
                mountPath: /data/db
          - name: mongo-sidecar
            image: cvallance/mongo-k8s-sidecar
            env:
              - name: MONGO_SIDECAR_POD_LABELS
                value: "app=${APPLICATION_NAME},component=mongo"
              - name: KUBERNETES_MONGO_SERVICE_NAME
                value: ${APPLICATION_NAME}-mongo
              - name: KUBE_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace

    volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: ${APPLICATION_NAME}   
        annotations:
          volume.beta.kubernetes.io/storage-class: aws-fast
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            # TODO: add parameter
            storage: ${VOLUME_MONGODB_CAPACITY}

- kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-zookeeper-config  
    labels:    
      app: ${APPLICATION_NAME}
      component: zookeeper
      role: config
  apiVersion: v1
  data:
    init.sh: |-
      #!/bin/bash
      set -x

      [ -z "$ID_OFFSET" ] && ID_OFFSET=1
      export ZOOKEEPER_SERVER_ID=$((${HOSTNAME##*-} + $ID_OFFSET))
      echo "${ZOOKEEPER_SERVER_ID:-1}" | tee /var/lib/zookeeper/data/myid
      sed -i "s/server\.$ZOOKEEPER_SERVER_ID\=[a-z0-9.-]*/server.$ZOOKEEPER_SERVER_ID=0.0.0.0/" /etc/kafka/zookeeper.properties

    zookeeper.properties: |-
      tickTime=2000
      dataDir=/var/lib/zookeeper/data
      dataLogDir=/var/lib/zookeeper/log
      clientPort=2181
      initLimit=5
      syncLimit=2
      server.1=${APPLICATION_NAME}-pzoo-0.${APPLICATION_NAME}-pzoo:2888:3888:participant
      server.2=${APPLICATION_NAME}-pzoo-1.${APPLICATION_NAME}-pzoo:2888:3888:participant
      server.3=${APPLICATION_NAME}-pzoo-2.${APPLICATION_NAME}-pzoo:2888:3888:participant
      server.4=${APPLICATION_NAME}-zoo-0.${APPLICATION_NAME}-zoo:2888:3888:participant
      server.5=${APPLICATION_NAME}-zoo-1.${APPLICATION_NAME}-zoo:2888:3888:participant

    log4j.properties: |-
      log4j.rootLogger=INFO, stdout
      log4j.appender.stdout=org.apache.log4j.ConsoleAppender
      log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
      log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

      # Suppress connection log messages, three lines per livenessProbe execution
      log4j.logger.org.apache.zookeeper.server.NIOServerCnxnFactory=WARN
      log4j.logger.org.apache.zookeeper.server.NIOServerCnxn=WARN



- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-pzoo
    labels:    
      app: ${APPLICATION_NAME}
      component: zookeeper
      role: service
  spec:
    ports:
    - port: 2888
      name: peer
    - port: 3888
      name: leader-election
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: zookeeper
      storage: persistent

- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-zoo
    labels:
      app: ${APPLICATION_NAME}
      component: zookeeper
      role: service
  spec:
    ports:
    - port: 2888
      name: peer
    - port: 3888
      name: leader-election
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: zookeeper
      storage: ephemeral

# the headless service is for PetSet DNS, this one is for clients
- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-zookeeper
    labels:    
      app: ${APPLICATION_NAME}
      component: zookeper-client
      role: service-client
  spec:
    ports:
    - port: 2181
      name: client
    selector:
      app: ${APPLICATION_NAME}
      component: zookeeper

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-pzoo
  spec:
    serviceName: "${APPLICATION_NAME}-pzoo"
    replicas: 3
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: zookeeper
          role: pdata
          storage: persistent
        annotations:
      spec:
        terminationGracePeriodSeconds: 10
        initContainers:
        - name: init-config
          image: solsson/kafka:0.11.0.1@sha256:3a77b3396b0890b0b0db880136c16bc83922588ed1d9a9ed82e32c1ae7621770
          command: ['/bin/bash', '/etc/kafka/init.sh']
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
          - name: data-${APPLICATION_NAME}
            mountPath: /var/lib/zookeeper/data
        containers:
        - name: zookeeper
          image: solsson/kafka:0.11.0.1@sha256:3a77b3396b0890b0b0db880136c16bc83922588ed1d9a9ed82e32c1ae7621770
          env:
          - name: KAFKA_LOG4J_OPTS
            value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties
          command:
          - ./bin/zookeeper-server-start.sh
          - /etc/kafka/zookeeper.properties
          ports:
          - containerPort: 2181
            name: client
          - containerPort: 2888
            name: peer
          - containerPort: 3888
            name: leader-election
          resources:
            requests:
              cpu: 10m
              memory: 100Mi
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - '[ "imok" = "$(echo ruok | nc -w 1 127.0.0.1 2181)" ]'
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
          - name: data-${APPLICATION_NAME}
            mountPath: /var/lib/zookeeper/data
        volumes:
        - name: config
          configMap:
            name: ${APPLICATION_NAME}-zookeeper-config
    volumeClaimTemplates:
    - metadata:
        name: data-${APPLICATION_NAME}
        labels:
          app: ${APPLICATION_NAME} 
          component: zookeper
        annotations:
          volume.beta.kubernetes.io/storage-class: aws-fast
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_ZOOKEEPER_CAPACITY}


- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-zoo
  spec:
    serviceName: "${APPLICATION_NAME}-zoo"
    replicas: 2
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: zookeeper
          role: edata
          storage: ephemeral
        annotations:
      spec:
        terminationGracePeriodSeconds: 10
        initContainers:
        - name: init-config
          image: solsson/kafka:0.11.0.1@sha256:3a77b3396b0890b0b0db880136c16bc83922588ed1d9a9ed82e32c1ae7621770
          command: ['/bin/bash', '/etc/kafka/init.sh']
          env:
          - name: ID_OFFSET
            value: "4"
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
          - name: data
            mountPath: /var/lib/zookeeper/data
        containers:
        - name: zookeeper
          image: solsson/kafka:0.11.0.1@sha256:3a77b3396b0890b0b0db880136c16bc83922588ed1d9a9ed82e32c1ae7621770
          env:
          - name: KAFKA_LOG4J_OPTS
            value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties
          command:
          - ./bin/zookeeper-server-start.sh
          - /etc/kafka/zookeeper.properties
          ports:
          - containerPort: 2181
            name: client
          - containerPort: 2888
            name: peer
          - containerPort: 3888
            name: leader-election
          resources:
            requests:
              cpu: 10m
              memory: 100Mi
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - '[ "imok" = "$(echo ruok | nc -w 1 127.0.0.1 2181)" ]'
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
          - name: data
            mountPath: /var/lib/zookeeper/data
        volumes:
        - name: config
          configMap:
            name: ${APPLICATION_NAME}-zookeeper-config
        - name: data
          emptyDir: {}


- kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-broker-config
    labels:
          app: ${APPLICATION_NAME}
          component: kafka
          role: config
  apiVersion: v1
  data:
    init.sh: |-
      #!/bin/bash
      set -x

      KAFKA_BROKER_ID=${HOSTNAME##*-}
      sed -i "s/#init#broker.id=#init#/broker.id=$KAFKA_BROKER_ID/" /etc/kafka/server.properties

      hash kubectl 2>/dev/null || {
        sed -i "s/#init#broker.rack=#init#/#init#broker.rack=# kubectl not found in path/" /etc/kafka/server.properties
      } && {
        ZONE=$(kubectl get node "$NODE_NAME" -o=go-template='{{index .metadata.labels "failure-domain.beta.kubernetes.io/zone"}}')
        if [ $? -ne 0 ]; then
          sed -i "s/#init#broker.rack=#init#/#init#broker.rack=# zone lookup failed, see -c init-config logs/" /etc/kafka/server.properties
        elif [ "x$ZONE" == "x<no value>" ]; then
          sed -i "s/#init#broker.rack=#init#/#init#broker.rack=# zone label not found for node $NODE_NAME/" /etc/kafka/server.properties
        else
          sed -i "s/#init#broker.rack=#init#/broker.rack=$ZONE/" /etc/kafka/server.properties
        fi
      }

    server.properties: |-
      # Licensed to the Apache Software Foundation (ASF) under one or more
      # contributor license agreements.  See the NOTICE file distributed with
      # this work for additional information regarding copyright ownership.
      # The ASF licenses this file to You under the Apache License, Version 2.0
      # (the "License"); you may not use this file except in compliance with
      # the License.  You may obtain a copy of the License at
      #
      #    http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing, software
      # distributed under the License is distributed on an "AS IS" BASIS,
      # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      # See the License for the specific language governing permissions and
      # limitations under the License.

      # see kafka.server.KafkaConfig for additional details and defaults

      ############################# Server Basics #############################

      # The id of the broker. This must be set to a unique integer for each broker.
      #init#broker.id=#init#

      #init#broker.rack=#init#

      # Switch to enable topic deletion or not, default value is false
      delete.topic.enable=true

      ############################# Socket Server Settings #############################

      # The address the socket server listens on. It will get the value returned from
      # java.net.InetAddress.getCanonicalHostName() if not configured.
      #   FORMAT:
      #     listeners = listener_name://host_name:port
      #   EXAMPLE:
      #     listeners = PLAINTEXT://your.host.name:9092
      #listeners=PLAINTEXT://:9092

      # Hostname and port the broker will advertise to producers and consumers. If not set,
      # it uses the value for "listeners" if configured.  Otherwise, it will use the value
      # returned from java.net.InetAddress.getCanonicalHostName().
      #advertised.listeners=PLAINTEXT://your.host.name:9092

      # Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
      #listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

      # The number of threads that the server uses for receiving requests from the network and sending responses to the network
      num.network.threads=3

      # The number of threads that the server uses for processing requests, which may include disk I/O
      num.io.threads=8

      # The send buffer (SO_SNDBUF) used by the socket server
      socket.send.buffer.bytes=102400

      # The receive buffer (SO_RCVBUF) used by the socket server
      socket.receive.buffer.bytes=102400

      # The maximum size of a request that the socket server will accept (protection against OOM)
      socket.request.max.bytes=104857600


      ############################# Log Basics #############################

      # A comma seperated list of directories under which to store log files
      log.dirs=/tmp/kafka-logs

      # The default number of log partitions per topic. More partitions allow greater
      # parallelism for consumption, but this will also result in more files across
      # the brokers.
      num.partitions=1

      # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
      # This value is recommended to be increased for installations with data dirs located in RAID array.
      num.recovery.threads.per.data.dir=1

      ############################# Internal Topic Settings  #############################
      # The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
      # For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
      offsets.topic.replication.factor=1
      transaction.state.log.replication.factor=1
      transaction.state.log.min.isr=1

      ############################# Log Flush Policy #############################

      # Messages are immediately written to the filesystem but by default we only fsync() to sync
      # the OS cache lazily. The following configurations control the flush of data to disk.
      # There are a few important trade-offs here:
      #    1. Durability: Unflushed data may be lost if you are not using replication.
      #    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
      #    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.
      # The settings below allow one to configure the flush policy to flush data after a period of time or
      # every N messages (or both). This can be done globally and overridden on a per-topic basis.

      # The number of messages to accept before forcing a flush of data to disk
      #log.flush.interval.messages=10000

      # The maximum amount of time a message can sit in a log before we force a flush
      #log.flush.interval.ms=1000

      ############################# Log Retention Policy #############################

      # The following configurations control the disposal of log segments. The policy can
      # be set to delete segments after a period of time, or after a given size has accumulated.
      # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
      # from the end of the log.

      # The minimum age of a log file to be eligible for deletion due to age
      log.retention.hours=168

      # A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
      # segments don't drop below log.retention.bytes. Functions independently of log.retention.hours.
      #log.retention.bytes=1073741824

      # The maximum size of a log segment file. When this size is reached a new log segment will be created.
      log.segment.bytes=1073741824

      # The interval at which log segments are checked to see if they can be deleted according
      # to the retention policies
      log.retention.check.interval.ms=300000

      ############################# Zookeeper #############################

      # Zookeeper connection string (see zookeeper docs for details).
      # This is a comma separated host:port pairs, each corresponding to a zk
      # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
      # You can also append an optional chroot string to the urls to specify the
      # root directory for all kafka znodes.
      zookeeper.connect=localhost:2181

      # Timeout in ms for connecting to zookeeper
      zookeeper.connection.timeout.ms=6000


      ############################# Group Coordinator Settings #############################

      # The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
      # The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
      # The default value for this is 3 seconds.
      # We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
      # However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
      group.initial.rebalance.delay.ms=0

    log4j.properties: |-
      # Licensed to the Apache Software Foundation (ASF) under one or more
      # contributor license agreements.  See the NOTICE file distributed with
      # this work for additional information regarding copyright ownership.
      # The ASF licenses this file to You under the Apache License, Version 2.0
      # (the "License"); you may not use this file except in compliance with
      # the License.  You may obtain a copy of the License at
      #
      #    http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing, software
      # distributed under the License is distributed on an "AS IS" BASIS,
      # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      # See the License for the specific language governing permissions and
      # limitations under the License.

      # Unspecified loggers and loggers with additivity=true output to server.log and stdout
      # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise
      log4j.rootLogger=INFO, stdout

      log4j.appender.stdout=org.apache.log4j.ConsoleAppender
      log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
      log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.kafkaAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log
      log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.stateChangeAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.stateChangeAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change.log
      log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.requestAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request.log
      log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.cleanerAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.cleanerAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner.log
      log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.controllerAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.controllerAppender.File=${kafka.logs.dir}/controller.log
      log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      log4j.appender.authorizerAppender=org.apache.log4j.DailyRollingFileAppender
      log4j.appender.authorizerAppender.DatePattern='.'yyyy-MM-dd-HH
      log4j.appender.authorizerAppender.File=${kafka.logs.dir}/kafka-authorizer.log
      log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout
      log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

      # Change the two lines below to adjust ZK client logging
      log4j.logger.org.I0Itec.zkclient.ZkClient=INFO
      log4j.logger.org.apache.zookeeper=INFO

      # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)
      log4j.logger.kafka=INFO
      log4j.logger.org.apache.kafka=INFO

      # Change to DEBUG or TRACE to enable request logging
      log4j.logger.kafka.request.logger=WARN, requestAppender
      log4j.additivity.kafka.request.logger=false

      # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output
      # related to the handling of requests
      #log4j.logger.kafka.network.Processor=TRACE, requestAppender
      #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender
      #log4j.additivity.kafka.server.KafkaApis=false
      log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender
      log4j.additivity.kafka.network.RequestChannel$=false

      log4j.logger.kafka.controller=TRACE, controllerAppender
      log4j.additivity.kafka.controller=false

      log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender
      log4j.additivity.kafka.log.LogCleaner=false

      log4j.logger.state.change.logger=TRACE, stateChangeAppender
      log4j.additivity.state.change.logger=false

      # Change to DEBUG to enable audit log for the authorizer
      log4j.logger.kafka.authorizer.logger=WARN, authorizerAppender
      log4j.additivity.kafka.authorizer.logger=false


- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-kafka
    labels:
      app: ${APPLICATION_NAME}
      component: kafka
  spec:
    ports:
    - port: 9092
    # [podname].broker.kafka.svc.cluster.local
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}
      component: kafka

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-kafka
    labels:
      app: ${APPLICATION_NAME}
      component: kafka
  spec:
    serviceName: "${APPLICATION_NAME}-kafka"
    replicas: 3
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          component: kafka
          role: data
        annotations:
      spec:
        terminationGracePeriodSeconds: 30
        initContainers:
        - name: init-config
          image: solsson/kafka-initutils@sha256:c275d681019a0d8f01295dbd4a5bae3cfa945c8d0f7f685ae1f00f2579f08c7d
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          command: ['/bin/bash', '/etc/kafka/init.sh']
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
        containers:
        - name: broker
          image: solsson/kafka:0.11.0.1@sha256:3a77b3396b0890b0b0db880136c16bc83922588ed1d9a9ed82e32c1ae7621770
          env:
          - name: KAFKA_LOG4J_OPTS
            value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties
          ports:
          - containerPort: 9092
          command:
          - ./bin/kafka-server-start.sh
          - /etc/kafka/server.properties
          - --override
          -   zookeeper.connect=${APPLICATION_NAME}-zookeeper:2181
          - --override
          -   log.retention.hours=-1
          - --override
          -   log.dirs=/var/lib/kafka/data/topics
          - --override
          -   auto.create.topics.enable=false
          resources:
            requests:
              cpu: 100m
              memory: 512Mi
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - 'echo "" | nc -w 1 127.0.0.1 9092'
          volumeMounts:
          - name: config
            mountPath: /etc/kafka
          - name: data-${APPLICATION_NAME}
            mountPath: /var/lib/kafka/data
        volumes:
        - name: config
          configMap:
            name: ${APPLICATION_NAME}-broker-config
    volumeClaimTemplates:
    - metadata:
        name: data-${APPLICATION_NAME}
        labels:
          app: ${APPLICATION_NAME}
          component: kafka
      annotations:
        volume.beta.kubernetes.io/storage-class: aws-fast
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_KAFKA_CAPACITY}


